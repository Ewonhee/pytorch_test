{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 tensor(2087.7729)\n",
      "199 tensor(1387.6254)\n",
      "299 tensor(923.4606)\n",
      "399 tensor(615.6820)\n",
      "499 tensor(411.5620)\n",
      "599 tensor(276.1622)\n",
      "699 tensor(186.3280)\n",
      "799 tensor(126.7120)\n",
      "899 tensor(87.1401)\n",
      "999 tensor(60.8665)\n",
      "1099 tensor(43.4174)\n",
      "1199 tensor(31.8259)\n",
      "1299 tensor(24.1231)\n",
      "1399 tensor(19.0030)\n",
      "1499 tensor(15.5984)\n",
      "1599 tensor(13.3337)\n",
      "1699 tensor(11.8267)\n",
      "1799 tensor(10.8234)\n",
      "1899 tensor(10.1553)\n",
      "1999 tensor(9.7101)\n",
      "2099 tensor(9.4134)\n",
      "2199 tensor(9.2155)\n",
      "2299 tensor(9.0834)\n",
      "2399 tensor(8.9953)\n",
      "2499 tensor(8.9364)\n",
      "2599 tensor(8.8970)\n",
      "2699 tensor(8.8707)\n",
      "2799 tensor(8.8531)\n",
      "2899 tensor(8.8413)\n",
      "2999 tensor(8.8334)\n",
      "Result: y=0.0020919134840369225+0.8533328771591187x)+-0.00036089104833081365x^2+[d]x^3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "dtype = torch.float\n",
    "device= torch.device(\"cpu\")\n",
    "\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
    "y= torch.sin(x)\n",
    "a= torch.randn((), device=device, dtype=dtype)\n",
    "b= torch.randn((), device=device, dtype=dtype)\n",
    "c= torch.randn((), device=device, dtype=dtype)\n",
    "d= torch.randn((), device=device, dtype=dtype)\n",
    "learning_rate=1e-6\n",
    "for t in range(3000):\n",
    "    y_pred=a+b*x+c*x**2+d*x**3\n",
    "    loss=torch.square(y_pred-y).sum()\n",
    "    if t % 100==99:\n",
    "        print(t,loss)\n",
    "    \n",
    "    grad_y_pred=2.0*(y_pred - y)\n",
    "    grad_a = grad_y_pred.sum()\n",
    "    grad_b = (grad_y_pred * x).sum()\n",
    "    grad_c = (grad_y_pred * x **2).sum()\n",
    "    grad_d = (grad_y_pred * x **3).sum()\n",
    "    \n",
    "    a -= learning_rate *grad_a\n",
    "    b -= learning_rate *grad_b\n",
    "    c -= learning_rate *grad_c\n",
    "    d -= learning_rate *grad_d\n",
    "\n",
    "print(f'Result: y={a}+{b}x)+{c}x^2+[d]x^3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAu/klEQVR4nO3dd3yV5f3/8dcnewdIQiCBJBBmgsywUVwgKgpVVBQUxYpUra1fR21/ttpardVaa60LAVGGIu4BgiLKHmETCDObhCQEQkjIvn5/5IApZSSQk/uMz/PxyCM5J+ec+80B8s5939d9XWKMQSmllALwsDqAUkopx6GloJRS6hQtBaWUUqdoKSillDpFS0EppdQpWgpKKaVOsVspiEh7EVkmIrtEJEVEfmO7/xkRyRGRLbaP6+yVQSmlVOOIva5TEJG2QFtjzCYRCQY2AmOBW4Hjxph/2GXDSimlLpiXvV7YGJML5Nq+LhGRXUC0vbanlFLq4tltT+G/NiISBywHegD/B9wNHAOSgUeNMUfO8JwpwBQAT//gfr0Tutg9p1JKuYKqmloKj1dycF9KoTEmojHPtXspiEgQ8BPwnDHmUxGJBAoBAzxL3SGmyed6Dd+2nU3yhmQuaRdq16xKKeUK/vX9Hl5dupf0F0ZvNMYkNea5dh19JCLewCfAXGPMpwDGmEPGmBpjTC3wDjDg/K8DH2zItGdUpZRyCTW1hgXJ2QzrFH5Bz7fn6CMBZgC7jDH/rHd/23oP+wWw43yv1cLfhy+3HKSssrrpgyqllAtZta+QnKMnuDWp/QU93557CkOBO4ErTxt++qKIbBeRbcAVwCPne6GWgd4cr6jm6225doyrlFLOb35yFi0CvBmZGHlBz7fn6KOVgJzhWwsb+1qBPl5ERQQyf0PWBbefUkq5uqLSSpak5DFxUCy+Xp4X9BpOc0Xz+P4xbMw4wp5DJVZHUUoph/Tppmyqagy39b/wX56dphRu6huNt6cwf0OW1VGUUsrhGGP4YH0mfWJa0K1NyAW/jtOUQliQLyMT2vDppmwqqmusjqOUUg5lQ/oR9heUcvuAmIt6HacpBYDb+rfnSFkVS1IOWR1FKaUcyofrMwn29WJ0z7bnf/A5OFUpDOsUTnQLfz7UaxaUUuqUo2WVfL09lzF9ogjwubjxQ05VCh4ewm3927Nq32EyD5dZHUcppRzCZ5tzqKyuvehDR+BkpQBwS1I7PATmJ+veglJKnTzB3KtdKIlRFz8VkNOVQttQfy7v2poFydlU19RaHUcppSy1KfMIew4db5K9BHDCUoC6E875JRUs211gdRSllLLUvHVZBPp4ckOvqCZ5PacshSu7tSYi2Jf5esJZKeXGik9U8c32g9zYO5pA36aZoMIpS8Hb04Nx/drxQ2o+ucUnrI6jlFKW+GJLDuVVtdzRRIeOwElLAeD2/jEY4MP1eoWzUsr9GGOYty6THtEhTbrWjNOWQkxYAJd1juDDDZl6wlkp5Xa2ZB0lNa+kyU4wn+S0pQAwYWAMh45V8P2ufKujKKVUs/pgfSYBPp7c2EQnmE9y6lK4sltr2ob6MXddhtVRlFKq2ZSUV/HV1lxu7BVFsJ93k762U5eCl6cH4/vHsGJvIemFpVbHUUqpZvH5loOcqKphfBMfOgInLwWA8QPa4+khfLBeh6cqpVyfMYY5azLoER1CryY8wXyS05dCZIgfI7pH8lFyFuVVOqW2Usq1bUg/wu5DJdw5KBaRMy1ueXGcvhQAJg6K5UhZFd/uyLM6ilJK2dWctRkE+3k12RXMp3OJUhgSH0ZcWABz1uoJZ6WU6yooqWDRjlzG9Wt30VNkn41LlIKHhzBhYCzJGUdIzTtmdRyllLKLj5KzqKoxTBwUa7dtuEQpAIzr1w4fLw/mrtUTzkop11NTW3cF89BOYcRHBNltOy5TCi0DfRh9SVs+25xDaUW11XGUUqpJLUvNJ+foCSYOtN9eArhQKQBMGBTL8Ypqvtx60OooSinVpGavzSAyxJerEyLtuh2XKoW+MS3o1iaYOWszMMZYHUcppZpExuFSlu8t4PYBMXh72vfHtkuVgogwcVAsKQePsSXrqNVxlFKqScxbl4mHSJNPfncmLlUKAGP7RBPk68XsNTo8VSnl/MqravgoOYtrEiOJDPGz+/ZcrhSCfL24uW80X2/LpfB4hdVxlFLqoizcnsuRsiq7n2A+yeVKAeCuIXFU1tTyoc6HpJRycrPXZtAxIpDB8WHNsj2XLIX4iCAu7RzOnLWZVOkCPEopJ7Ujp5jNmUftNs/RmbhkKQDcPSSOvGPlLEk5ZHUUpZS6IO+vScff25Ob+rZrtm26bClc3rU17Vv5897qdKujKKVUoxWVVvL5loPc3C+aUP+mXUjnXFy2FDw9hLsGxbE+vYidB3U+JKWUc/lgfSaV1bVMGhzXrNt12VIAuDWpPf7enry/Jt3qKEop1WBVNbXMWZvBpZ3D6RwZ3KzbdulSCA3wZmyfaD7fksPRskqr4yilVIMsSTlEbnE5dw+Ja/Zt260URKS9iCwTkV0ikiIiv7Hd30pEvhORvbbPLe2VAWDSkFjKq2qZvyHLnptRSqkmM2t1GjGtAri8a+tm37Y99xSqgUeNMd2BQcCDIpIAPAksNcZ0BpbabttNtzYhDOzQitlrM6ip1fmQlFKObUdOMRvSj3DX4Fg8PZpnGGp9disFY0yuMWaT7esSYBcQDYwB3rM97D1grL0ynHT3kDiyj5xg6S4dnqqUcmyzVqcT4OPJLUntLdl+s5xTEJE4oA+wDog0xuRCXXEAZ9w/EpEpIpIsIskFBQUXtf0RCZG0DfXjfZ0PSSnlwAqPV/DlloPc3Lddsw5Drc/upSAiQcAnwG+NMQ0eG2qMmWaMSTLGJEVERFxUBi9PDyYOimXlvkL25Zdc1GsppZS9fLg+k8qaWiYNaZ55js7ErqUgIt7UFcJcY8yntrsPiUhb2/fbAvn2zHDS+P7t8fHy4N1V6c2xOaWUapSqmlpm24ahdmrdvMNQ67Pn6CMBZgC7jDH/rPetL4FJtq8nAV/YK0N9YUG+/KJ3NJ9syuZIqQ5PVUo5lm935HHoWAX3DI2zNIc99xSGAncCV4rIFtvHdcALwAgR2QuMsN1uFpOHdaC8qpZ5OnuqUsrBzFqdTmxYAJd3af5hqPV52euFjTErgbONp7rKXts9l65tgrm0czjvrU7nvks74uPl0tfuKaWcxPbsYjZmHOFPoxPwsGAYan1u91Px3mEdyC+p4JvtB62OopRSAMxYeYBAH0/GJTXfbKhn43alMLxLBJ1aBzFjZRrG6MVsSilr5Raf4OttudzWP4YQP2uGodbndqUgIkwe2oEdOcdYl1ZkdRyllJubtTqdWmMsP8F8ktuVAsBNfaNpGeDNjJVpVkdRSrmx4xXVzFuXybU92tK+VYDVcQA3LQU/b08mDorl+12HSC8stTqOUspNLUjOoqS8ml9e2sHqKKe4ZSkA3DkoFi8P4d1VureglGp+NbWGmavS6Bfbkj4xdp0sulHcthRah/hxQ68oFmzMpvhEldVxlFJuZnFKHllFJ7jPgfYSwI1LAeqGp5ZV1vChXsymlGpm01ccIKZVACMS2lgd5b+4dSkkRoUyuGMY761Op6qm1uo4Sik3sTHjCJsyjzJ5aJwlayaci1uXAtTtLRwsLmfRjjyroyil3MT0FQcI8fOybM2Ec3H7UriyW2s6hgcybfl+vZhNKWV3mYfLWJySxx0DYwn0tdtMQxfM7UvBw0OYcllHduQcY/X+w1bHUUq5uJmr0vAQ4e4hcVZHOSO3LwWAsX2iiQj25a2f9lsdRSnlwopPVPFRchY39oqiTaif1XHOSEuBuovZ7hkax4q9haQcLLY6jlLKRc1bl0lZZQ2ThznWMNT6tBRsJgyMJdDHk2nLD1gdRSnlgsqrapi5Ko1LO4fTIzrU6jhnpaVgE+rvzR0DY/h6Wy5ZRWVWx1FKuZhPN+VQUFLB1OHxVkc5Jy2FeiYP64CHoBPlKaWaVE2tYdry/fRsF8qQ+DCr45yTlkI9bUP9GdM7mg83ZFKk6zgrpZrI4pQ80g+XMXV4PHXL1zsuLYXTTLmsI+VVtcxek2F1FKWUCzDG8OaP++kQHsg1iY41pcWZaCmcpktkMFd1a817a9I5UVljdRyllJNbvf8w23OKmXJZR4eb0uJMtBTO4P7h8RSVVvLxxiyroyilnNybP+4nItiXX/SJtjpKg2gpnEH/uJb0iWnBOyvSqNaJ8pRSF2h7djEr9xVy77AO+Hl7Wh2nQbQUzkBEmDo8nsyiMp0oTyl1wd5avp9gXy/uGBhjdZQG01I4ixHdI4mPCOSNH3WiPKVU46UXlrJoey4TB8cS4udtdZwG01I4Cw8P4YHLO7Er9xg/pOZbHUcp5WSmrTiAl6cH9wyNszpKo2gpnMONvaNo19Kf137Yp3sLSqkGyy8p5+ON2Yzr147WwY458d3ZaCmcg7enB1OHx7Ml66hOq62UarB3lh+gptZw/2UdrY7SaFoK5zGuXzsiQ3z5zw/7rI6ilHICh49XMGdtJmN6RREbFmh1nEbTUjgPP29P7ru0I2sOHGZjRpHVcZRSDm7mqjTKq2t44IpOVke5IFoKDXDHwBhaBfro3oJS6pyKy6p4b3UG113Slk6tg6yOc0G0FBogwMeLe4d1YNnuAnbk6CI8Sqkzm7U6neMV1TzkpHsJoKXQYHcOjiXYz4vXl+neglLqf5WUVzFzVRojEiLp3jbE6jgXTEuhgUL8vJk0OI5vU/LYl19idRyllIOZvTaD4hNV/PpK591LAC2FRpk8rAN+Xp68sWy/1VGUUg6krLKa6SvSGN4lgp7tWlgd56LYrRREZKaI5IvIjnr3PSMiOSKyxfZxnb22bw+tAn2YMDCGL7YeJONwqdVxlFIOYt66uoW5nH0vAey7pzALGHWG+18xxvS2fSy04/btYsplHfHyEF7TkUhKKaC8qoZpyw8wuGMYSXGtrI5z0exWCsaY5YDLDexvHeLHhIGxfLY5h/RC3VtQyt0tSM4iv6TCJfYSwJpzCg+JyDbb4aWWZ3uQiEwRkWQRSS4oKGjOfOc19XLdW1BKQUV1DW/+uJ9+sS0ZHB9mdZwm0dyl8CYQD/QGcoGXz/ZAY8w0Y0ySMSYpIiKimeI1TOtgPyYOiuWzzdmk6d6CUm7row1ZHCwu57dXd0bE8ZfabIhGlYKIXNREHsaYQ8aYGmNMLfAOMOBiXs9KU4fH4+PlwWtL91odRSllgfKqGv6zbB8D4loxrFO41XGaTINKQUSGiMhOYJftdi8ReaOxGxORtvVu/gLYcbbHOrqIYF/uHBTL51ty2F9w3Oo4SqlmNm9dJoeOVfDIiC4us5cADd9TeAW4BjgMYIzZClx2rieIyAfAGqCriGSLyL3AiyKyXUS2AVcAj1xwcgdw//B4fL08dU4kpdzMicoa3vhxP4M7hrnMuYSTvBr6QGNM1mltWHOex99+hrtnNHR7ziA8yJe7BsfyzooDPHRlJ+IjnHMCLKVU48xZm0Hh8QremNDX6ihNrqF7ClkiMgQwIuIjIo9hO5Tk7qZc1hFfL0/+recWlHILpRXVvPXTfi7tHM6ADs5/XcLpGloKU4EHgWggm7rRQw/aKZNTCQvy5a4hsXy59aDOiaSUG3h/TQaHSyt5ZEQXq6PYRYNKwRhTaIyZYIyJNMa0NsZMNMbo+pQ2918Wj7+3J68u1XMLSrmykvIq3l6+nyu6RtA35qyXWTm1Bp1TEJF3gf9Zud4YM7nJEzmhVoE+3D0kjjd/2s8Dl8c79bS5Sqmzm7UqnaNlVS67lwANP3z0NfCN7WMpEALoOMx67r8snmBfL/6xeLfVUZRSdlB8oop3Vhzg6u6RTj8T6rk0aE/BGPNJ/du24abf2yWRkwoN8Ob+4fG8tHg3GzOK6BfreieglHJnM1amcay8mkdGdLY6il1d6DQXnYGYpgziCu4ZGkd4kC8vfrsbY/7naJtSykkVHq9g+ooDXHdJGxKjQq2OY1cNvaK5RESOnfwMfAX8zr7RnE+AjxcPX9WJdWlFLN9baHUcpVQT+c8P+6ioruWxkV2tjmJ3DR19FGyMCan3ucvph5RUnfH9Y2jX0p+XFqdSW6t7C0o5u6yiMuauy+DWpPZ0dIMLVM95TkFEznm5njFmU9PGcX4+Xh48cnUXHl2wlUU78ri+Z9vzP0kp5bBe+X4PHiL85irXPpdw0vlONJ91amvqhqhe2YRZXMbYPtG8vXw/L3+3m2sSI/Hy1KWwlXJGu/NK+GxzDlMu60ibUD+r4zSLc5aCMeaK5griSjw9hEdHduX+2Rv5ZFM2t/XXc/JKOaOXFu8myNeLXw2PtzpKs2nwhHgi0gNIAE7VpTHmfXuEcgUjEyLp3b4Fr36/lzG9o/Hz9rQ6klKqEZLTi/h+1yEev6YrLQJ8rI7TbBo6+uhp4DXbxxXAi8CNdszl9ESEJ67pysHicuaszbA6jlKqEYwx/P3bVCKCfblnaJzVcZpVQw92jwOuAvKMMfcAvQBfu6VyEUM6hXNp53D+s2wfxSeqrI6jlGqgH3cXsCH9CA9f1ZkAnwYfUHEJDS2FE7YlNKtFJATIBzraL5br+P213Sk+UcUby3SyPKWcQU1t3V5CbFgA4/u3tzpOs2toKSSLSAvq1lXeCGwC1tsrlCtJiArhpj7teHd1OtlHyqyOo5Q6j082ZZOaV8JjI7vi7YYjBxt68doDxpijxpi3gBHAJNthJNUAj13TBQGdLE8pB1dWWc3LS3bTu30LRrvpNUYNPdH8hYjcISKBxph0Y8w2ewdzJW1D/bl3WAc+33KQ7dnFVsdRSp3FO8vTOHSsgqeu785pyw+7jYbuG/0TGAbsFJEFIjJORNzjSo4mMvXyeFoF+vDcwp06WZ5SDij/WDlvL9/PtT3akBTnvrMcN/Tw0U/GmAeoO7k8DbiVupPNqoFC/Lz57dWdWXugiB9S9a1TytH887s9VNXU8rtR3ayOYqkGn0UREX/gZurWa+4PvGevUK7q9gExdAwP5G+LUqmuqbU6jlLKJjXvGB8lZ3HnoDjiwgOtjmOphp5TmA/som6uo9eBeGPMr+0ZzBV5e3rwxKhu7Ms/zkfJ2VbHUUrZPL8wlSDfuqnv3V1D9xTepa4IphpjfrBds6AuwDWJkSTFtuSf3+2hpFwvaFPKaj/tKWD5ngIevqqzW01ncTYNLYVNwI0i8qCITBaRASLifgN4m4CI8MfRCRQer+D1ZfutjqOUW6upNfxt4S5iWgVw5+BYq+M4hHP+YBeRK0RkMfANcC3QlrpJ8Z4CtovIn21XOKtG6NW+BeP6tWPmyjTSC0utjqOU25q/IYvUvBJ+N6obvl46aSWcf5bU64D7jDGZp39DRLyA0dRdzKarsDXSE9d0ZdH2XJ5buIt37kqyOo5Sbqe4rIp/LNnNgA6tuO6SNlbHcRjn3FMwxjx+pkKwfa/aGPO5Lst5YVqH+PHQlZ35buchVuwtsDqOUm7nle/3cLSskqdvSHDbC9XOpKGjj2aLSGi923EistR+sdzD5GFxxIYF8OzXO3WIqlLNaM+hEmavzWD8gBgSo0LP/wQ30tCTxSuBdSJynYjcBywB/mW3VG7C18uTP1zXnT2HjjNv/Rl3yJRSTcwYw1++2kmgjyePjexqdRyH06CJwo0xb4tICrAMKAT6GGPy7JrMTYxMiGRopzBeXrKHG3pG0TJQh8QpZU9Ldh5i5b5CnrkhgVb6/+1/NPTw0Z3ATOAuYBawUER62TGX2xAR/jQ6kZLyKv71/R6r4yjl0sqravjrNzvpEhnExEE6BPVMGnr46GZgmDHmA2PM76mb6mKW3VK5ma5tgpk4KJY56zJJzTtmdRylXNb0FQfIKjrB0zck4uWGayU0REMnxBtrjMmvd3s9MNBuqdzQI1d3IcTPiz99nqKzqCplB7nFJ3h92X5GJbZhaKdwq+M4rPNdvPaUiJxxDlljTKWIXCkio+0Tzb20DPThyWu7sT69iE835VgdRymX89w3u6gxhv93fXerozi0851o3g58JSLl1E11UQD4AZ2B3sD3wPNneqKIzKTu4rZ8Y0wP232tgPlAHJAO3GqMOXKxfwhXcUu/9szfkMXfFu3i6u6RhAZ4Wx1JKZewYm8BX2/L5bdXd6Z9qwCr4zi08x0+GmeMGQosBlIAT+AYMAcYYIx5xBhztiuvZgGjTrvvSWCpMaYzsNR2W9l4eAjPju1BUWkl/1iiS3cq1RTKq2r40xcpxIUFMHV4vNVxHN75SqGfiMQCE4AvgbeB94ENgP+5nmiMWQ4UnXb3GH5eh+E9YGwj87q8xKhQ7hocx5x1Gbp0p1JN4O2fDpBWWMqzY3vg563zG53P+UrhLeBboBuQXO9jo+1zY0UaY3IBbJ9bn+2BIjJFRJJFJLmgwL2mgfi/kV0ID/Llqc+3U1OrJ52VulDphaW8/uM+Rvdsy6WdI6yO4xTON/fRv40x3YGZxpiO9T46GGM62jOYMWaaMSbJGJMUEeFef5khft48dX13tmYX84Fe6azUBTHG8KcvU/Dx9OCPoxOsjuM0Gjok9VdNtL1DItIWwPZZFys+ixt7RTG4YxgvLd5N4fEKq+Mo5XQWbs9j+Z4CHh3ZhcgQP6vjOI3mvnrjS2CS7etJwBfNvH2nISI8OzaR0opqnl+4y+o4SjmVkvIq/vJ1ColRIdypVy43it1KQUQ+ANYAXUUkW0TuBV4ARojIXurWYXjBXtt3BZ1aB3P/8I58uimHlXsLrY6jlNN45bu95JdU8NwvLtErlxupQRPiXQhjzO1n+dZV9tqmK/r1lZ1ZtD2P33+2jSW/HY6/j46eUOpctmUfZdbqNO4YEEPv9i2sjuN0tEIdnJ+3J8/fdAlZRSd4RSfMU+qcqmpqeeLjbYQH+fLEqG5Wx3FKWgpOYFDHMG4f0J7pKw6wI0evXVDqbKYtP0BqXgl/HduDUH+dEeBCaCk4iSev7U5YkC9PfLyNKl2lTan/sb/gOK8u3cv1l7RlZKKuuXyhtBScRKi/N3+5MZGduceYsTLN6jhKOZTaWsOTn2zD39uTZ25MtDqOU9NScCKjerRhZEIkr3y3h/TCUqvjKOUw5q7PZEP6EZ66vjsRwb5Wx3FqWgpORET4y5ge+Hh68IfPtuu6C0pRt07C3xelcmnncMb1a2d1HKenpeBk2oT68eR13Vi9/zBz1+kUGMq9GWN46rMd1NQanv/FJYiI1ZGcnpaCE7pjQAzDOoXz/MJdZBWVWR1HKct8simHpan5PDqyi66T0ES0FJyQiPD3cT3xFOGxBVup1ZlUlRs6ePQEf/4qhQFxrZg8tIPVcVyGloKTim7hzx9HJ7AurYj316RbHUepZmWM4XefbKOm1vDSLT3x8NDDRk1FS8GJ3ZLUjiu6RvDCt6mk6Wgk5Ubmrstkxd5C/nBdd2LDAq2O41K0FJyYiPDCzT3x8fTg8QVbdUEe5RYyDpfy/MJdXNo5nAkDY6yO43K0FJxcZIgffx6TSHLGEWbqRW3KxdXWGh5fsA1PD+HvN/fU0UZ2oKXgAsb2jmZEQiQvLdnN7rwSq+MoZTczV6WxPr2Ip29IJKrFOZeJVxdIS8EFiAh/u+kSQvy8+M2HmymvqrE6klJNbndeCS8u3s3V3SO5uW+01XFclpaCiwgP8uWlW3qRmlfCi9/utjqOUk2qvKqGhz/YTIifNy/crBep2ZOWggu5omtr7h4Sx8xVafy0p8DqOEo1mRcWpbL7UAn/uKUn4UE6t5E9aSm4mCev7UaXyCAeW7CVw8crrI6j1EX7IfUQs1anM3loBy7v2trqOC5PS8HF+Hl78ur4PhSXVfG7T7bppHnKqeWXlPP4gm10bxvC767tanUct6Cl4ILq/gN14/td+TppnnJatbWGRz/ayvGKav49vje+Xro+eXPQUnBR9wyJ49LO4fz1m506TFU5pZmr0lixt5A/jk6gc2Sw1XHchpaCi/LwEF6+tRfBft48MHcjpRXVVkdSqsG2ZR/lxW93MyIhUq9abmZaCi6sdbAfr47vTVphKU99vkPPLyinUFxWxQNzNxEe5MOLetVys9NScHFD4sP5zVVd+GxzDvM3ZFkdR6lzMsbw2MdbySsu5z8T+tIy0MfqSG5HS8ENPHRlJ4Z1CufpL1PYlXvM6jhKndWMlWl8t/MQv7+uO31jWlodxy1pKbgBTw/hX+N7E+rvzYNzN3Fczy8oB7Qxo4gXFqVyTWIkk4fGWR3HbWkpuInwIF/+fXsf0g+X8vtPt+v5BeVQikoreWjeZqJa+PPiuF56HsFCWgpuZFDHMB4d2ZWvth7k3VXpVsdRCoCaWsNv52/h8PFK3pjQl1B/b6sjuTUtBTfzq+HxjEyI5LmFu1iz/7DVcZTipcW7Wb6ngD+PSaRHdKjVcdyeloKbOXn9QlxYAA/O20TO0RNWR1Ju7OttB3nrp/3cMTCG2wfo9QiOQEvBDQX7eTPtriQqq2uZOnujrr+gLLEr9xiPL9hGUmxLnrkh0eo4ykZLwU3FRwTxym292Z5TzB8+0xPPqnkdLatkyuxkQvy9eGNiX3y89EeRo9C/CTc2IiGS317dmU835TBrdbrVcZSbqK6p5dcfbOZQcQVvTexH62A/qyOperQU3NzDV3bm6u6RPPv1Tn7cnW91HOUGnl+Yyoq9hTw7NpE+eoGaw7GkFEQkXUS2i8gWEUm2IoOq4+EhvDq+N13bhPDQvM06o6qyq9lr0pm5Ko17hsZxW389seyIrNxTuMIY09sYk2RhBgUE+noxY1ISAT6eTJ61gYISXbFNNb0fd+fzzFc7uapba566PsHqOOos9PCRAiCqhT/TJyVxuLSCKbOTdUSSalK780p4aN5mukYG8+/b++DpoVcsOyqrSsEAS0Rko4hMOdMDRGSKiCSLSHJBgS5C3xx6tmvBv27rzebMozz+sS7lqZpGfkk5k2dtIMDHkxl3JxHo62V1JHUOVpXCUGNMX+Ba4EERuez0BxhjphljkowxSREREc2f0E2N6tGWJ0bVTYXxjyW7rY6jnNyJyhrue38jRaWVzJjUn7ah/lZHUudhSWUbYw7aPueLyGfAAGC5FVnU//rV8Hiyik7w+rL9RAT5cvfQDlZHUk6oqqaWB+dtYnv2Ud6c2I9L2ukUFs6g2fcURCRQRIJPfg2MBHY0dw51diLCs2MSGZEQyZ+/3snX2w5aHUk5GWMMT36ynR9S83l2bA+uSWxjdSTVQFYcPooEVorIVmA98I0x5lsLcqhz8PL04LXb+5AU25L/m7+V1fsKrY6knMgL36byyaZsHrm6CxMGxlodRzVCs5eCMeaAMaaX7SPRGPNcc2dQDePn7cn0u/rTITyQKbM3siOn2OpIyglMX3GAt386wJ2DYnn4qk5Wx1GNpENS1TmFBngza3J/Qvy8uPvdDRwoOG51JOXAPt2UzV+/2cV1l7ThmRsTdbEcJ6SloM6rbag/7987EGMME6avI6uozOpIygEt2p7L4x9vY3DHMF65rbdei+CktBRUg3RqHcTsewdSVlnD7e+s5aCuw6Dq+X7nIX79wWZ6t2/B9ElJ+Hp5Wh1JXSAtBdVgCVEhzL53AMVlVUyYvo78Y+VWR1IO4Kc9BTwwdxOJUSG8e09/vTjNyWkpqEbp2a4Fsyb359CxciZMX8fh4zpPkjtbvb+QKe8n06l1EO9PHkiIn66v7Oy0FFSj9Yttxcy7+5N1pIwJ09dRqMXgllbvL+TeWcnEhgUw55cDCQ3QQnAFWgrqggzqGMaMSf1JP1zKbW+v4ZAeSnIrP+7O5553N9C+lT9zfjmQVoE+VkdSTURLQV2woZ3CeX/yQPKKy7n17TVkH9FRSe5gSUoe99kOGX04ZbCunOZitBTURRnQoRVzfjmQI6WV3Pb2WjIOl1odSdnRV1sP2k4qhzLvl4N0D8EFaSmoi9YnpiXz7htEWWU1t7y1Rldvc1EfbcjiNx9upm9sSz2H4MK0FFST6BEdyvz7ByMC495azboDh62OpJqIMYbXlu7liU+2MaxzBO/dM4AgHXbqsrQUVJPpEhnMpw8MpXWwL3fOXM+i7blWR1IXqabW8McvdvDyd3u4qU80MyYl4e+jF6a5Mi0F1aSiW/jz8dQhXBIdygPzNvHe6nSrI6kLVF5VwwNzNzJnbSZTh8fz8q298PbUHxmuTv+GVZNrGejD3F8O5OrukTz9ZQrPL9xFTa0u7elMCo9XMGH6OpbsPMTTNyTw5LXddHI7N6GloOzCz9uTNyf05a7BsUxbfoD73k+mpLzK6liqAXblHmPMf1axI6eY/9zel3t05T23oqWg7MbL04O/jOnBs2MS+WlPATe9sZrMw3otgyNbnJLHzW+upqbW8PHUIVzfs63VkVQz01JQdnfn4DhmTx5AfkkFY15fyZr9OjLJ0RhjeH3ZPu6fvZHOkcF8+dBQXVPZTWkpqGYxpFM4Xzw4lFaBPkycsY63ftpPrZ5ncAjFJ6qYMnsjLy3ezdjeUcyfMojWIXqVsrvSUlDNJi48kM8fHMo1iZG8sCiVKbOTKS7T8wxW2p5dzOjXVrAsNZ8/jk7gldt64+etQ07dmZaCalbBft68fkdfnr4hgZ/2FHD9ayvYln3U6lhuxxjDnLUZ3PzmaqprDPPvH8y9wzroCCOlpaCan4hwz9AOfHT/YGprDePeXMO05ft12GozOVpWyUPzNvPU5zsYHB/GNw9fSr/YllbHUg5CS0FZpk9MS755+FIu7xrB8wtTueOdtTrTqp0t31PAyFeWszglj8ev6cq7d/fXSe3Uf9FSUJZqGejD23f246VxPUk5eIxR/1rBxxuzMUb3GprSicoanv5iB3fNXE+IvzefPziUB6/ohIeHHi5S/01ntVKWExFuSWrPoI5hPPrRVh5bsJVvd+Ty5zE9iG7hb3U8p7dybyH/7/PtZBwu456hcfxuVDc9mazOSpzhN7KkpCSTnJxsdQzVDGpqDe+uSuPlJXsQgUdHdmXS4Fi8dM6dRisqreS5b3bxyaZs4sICeP6mSxgSH251LNWMRGSjMSapUc/RUlCOKKuojD99sYNluwvoER3Cc2MvoVf7FlbHcgq1tYaPN2XzwqJUjp2oYurweB66spPuHbghLQXlUowxfLM9lz9/tZOCkgpu6hPN46O60jZUDymdzfq0Iv7ydQo7co7RN6YFf7upJ13bBFsdS1nkQkpBzykohyUijO4ZxfAuEbzx435mrExj4Y5c7r8snvuHdyTAR//5npR5uIy/f5vKN9tzaRvqx6vje3Njryi97kA1mu4pKKeRVVTGC9+m8s22XMKDfJg6PJ4JA2PdetGX7CNlvL5sHwuSs/HyFKYOj+f+y+Ld+j1RP9PDR8otbMwo4p/f7WHVvsOEB/nyq8vjmTAwxq2OmR88eoI3f9zPhxsyEYTbB7TngSs6EalzFql6tBSUW1mfVsQr3+1hzYHDtAr0YcLAGO4cFOvSk7ltyz7K9BVpfLM9FwFu7d+eB6/opEN31RlpKSi3tO7AYd5ZkcbS1EN4eQg39Ipi0uA4erYLdYlj6hXVNXy/M5/31qSzPq2IIF8vxvdvz91D42jXMsDqeMqB6Ylm5ZYGdgxjYMcw0gpLmbUqjQUbs/l0Uw5dIoO4Nak9Y/tEEx7ka3XMRkvNO8b8DVl8vjmHI2VVRLfw56nru3Nb//YE+3lbHU+5KN1TUC7nWHkVX209yILkbLZkHcXLQxjWOZxRiW24OiHSYQvCGMOeQ8f5dkcei3bkkppXgrenMDKhDbf2b8+wTuF46rQUqhH08JFSp9l7qISPN2azcEcuWUUn8BBIim3FFd1aMyQ+jMSoEEuvli6tqGZ9WhGr9hXyQ2o+BwpLEYGk2JZcd0lbxvSO1gnr1AVzmlIQkVHAq4AnMN0Y88K5Hq+loC6WMYZduSUsTsljcUoeqXklAAT7ejGgQyv6xbWkR1QoiVEhhNlpT8IYQ1bRCbblHGVbdjGbM4+wOfMo1bUGH08PBnRoxagebRiZEOnSJ8tV83GKUhART2APMALIBjYAtxtjdp7tOVoKqqnll5Sz9kARa/YfZu2Bw6QVlp76XttQPzpGBBIbFkhsqwDatwogLNCHVraPID8vvD08/muG0eqaWsqraymrqKbweCUFxysoLKkg5+gJ0gpLOVBYyoGC45SUVwPg4+lBQlQIg+PDGBofTlJcS7caUquah7OcaB4A7DPGHAAQkQ+BMcBZS0GpptY62I8be0VxY68ooG7hmZ0Hj5Fy8BgpB4tJO1zGou25HDnHcqFeHoKXp1BdY6g+xwJBUaF+dIgI5MZeUSREhdAzugVd2wTj46WT/CnHY0UpRANZ9W5nAwNPf5CITAGm2G5WiMiOZsjmDMKBQqtDOAineC8ygDX234xTvBfNRN+Ln3Vt7BOsKIUzDZ/4n1+zjDHTgGkAIpLc2F0gV6Xvxc/0vfiZvhc/0/fiZyLS6OPuVuy/ZgPt691uBxy0IIdSSqnTWFEKG4DOItJBRHyA8cCXFuRQSil1mmY/fGSMqRaRh4DF1A1JnWmMSTnP06bZP5nT0PfiZ/pe/Ezfi5/pe/GzRr8XTnHxmlJKqeahY+KUUkqdoqWglFLqFIcuBREZJSK7RWSfiDxpdR6riEh7EVkmIrtEJEVEfmN1JquJiKeIbBaRr63OYiURaSEiH4tIqu3fx2CrM1lFRB6x/f/YISIfiIhbzRUiIjNFJL/+NV0i0kpEvhORvbbPLc/3Og5bCrbpMF4HrgUSgNtFJMHaVJapBh41xnQHBgEPuvF7cdJvgF1Wh3AArwLfGmO6Ab1w0/dERKKBh4EkY0wP6gaxjLc2VbObBYw67b4ngaXGmM7AUtvtc3LYUqDedBjGmErg5HQYbscYk2uM2WT7uoS6//jR1qayjoi0A64HpludxUoiEgJcBswAMMZUGmOOWhrKWl6Av4h4AQG42fVPxpjlQNFpd48B3rN9/R4w9nyv48ilcKbpMNz2B+FJIhIH9AHWWRzFSv8CngBqLc5htY5AAfCu7VDadBEJtDqUFYwxOcA/gEwgFyg2xiyxNpVDiDTG5ELdL5dA6/M9wZFLoUHTYbgTEQkCPgF+a4w5ZnUeK4jIaCDfGLPR6iwOwAvoC7xpjOkDlNKAwwOuyHasfAzQAYgCAkVkorWpnJMjl4JOh1GPiHhTVwhzjTGfWp3HQkOBG0UknbpDileKyBxrI1kmG8g2xpzca/yYupJwR1cDacaYAmNMFfApMMTiTI7gkIi0BbB9zj/fExy5FHQ6DBupW31+BrDLGPNPq/NYyRjze2NMO2NMHHX/Jn4wxrjlb4TGmDwgS0ROzoR5Fe47BX0mMEhEAmz/X67CTU+6n+ZLYJLt60nAF+d7ghWzpDbIBU6H4aqGAncC20Vki+2+PxhjFloXSTmIXwNzbb84HQDusTiPJYwx60TkY2ATdaP1NuNm012IyAfA5UC4iGQDTwMvAB+JyL3UFect530dneZCKaXUSY58+EgppVQz01JQSil1ipaCUkqpU7QUlFJKnaKloJRS6hQtBaWakIgctzqDUhdDS0EppdQpWgrKLYlIfxHZJiJ+IhJom4e/x2mP+buIPFDv9jMi8qiIBInIUhHZJCLbReR/Zu8Vkcvrr/UgIv8RkbttX/cTkZ9EZKOILD45DYFSjkBLQbklY8wG6qYA+CvwIjDHGLPjtId9CNxW7/atwAKgHPiFMaYvcAXwsm1qhfOyzWH1GjDOGNMPmAk8dzF/FqWaksNOc6FUM/gLdXNslVO3QMt/McZsFpHWIhIFRABHjDGZth/sz4vIZdRN3x0NRAJ5DdhmV6AH8J2tRzypm+pZKYegpaDcWSsgCPAG/Kibevp0HwPjgDbU7TkATKCuJPoZY6psM7aevvRjNf+9J37y+wKkGGPcdtlM5dj08JFyZ9OAPwJzgb+f5TEfUjcb6zjqCgIglLo1HapE5Aog9gzPywASRMRXREKpm7UTYDcQcXItZRHxFpHEJvnTKNUEdE9BuSURuQuoNsbMs60HvlpErjTG/FD/ccaYFBEJBnJOrmBFXYl8JSLJwBYg9fTXN8ZkichHwDZgL3WzdmKMqRSRccC/bWXhRd1Kcu46A7ByMDpLqlJKqVP08JFSSqlTtBSUUkqdoqWglFLqFC0FpZRSp2gpKKWUOkVLQSml1ClaCkoppU75/9V5hslKTc1TAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "x=np.arange(-10,10,0.01)\n",
    "plt.xlabel(\"x value\")\n",
    "plt.ylabel(\"f(x)value\")\n",
    "\n",
    "plt.axis([0, 10, 0, 25])\n",
    "\n",
    "plt.plot(x,(x-5)**2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predic(before training) 4 tensor(4.)\n",
      "\tgrad: 1.0 2.0 tensor(-1.)\n",
      "\tgrad: 2.0 4.0 tensor(-3.9600)\n",
      "\tgrad: 3.0 6.0 tensor(-8.5536)\n",
      "progress: 0 tensor(8.1293)\n",
      "\tgrad: 1.0 2.0 tensor(-0.8649)\n",
      "\tgrad: 2.0 4.0 tensor(-3.4249)\n",
      "\tgrad: 3.0 6.0 tensor(-7.3977)\n",
      "progress: 1 tensor(6.0807)\n",
      "\tgrad: 1.0 2.0 tensor(-0.7480)\n",
      "\tgrad: 2.0 4.0 tensor(-2.9620)\n",
      "\tgrad: 3.0 6.0 tensor(-6.3980)\n",
      "progress: 2 tensor(4.5483)\n",
      "\tgrad: 1.0 2.0 tensor(-0.6469)\n",
      "\tgrad: 2.0 4.0 tensor(-2.5618)\n",
      "\tgrad: 3.0 6.0 tensor(-5.5334)\n",
      "progress: 3 tensor(3.4021)\n",
      "\tgrad: 1.0 2.0 tensor(-0.5595)\n",
      "\tgrad: 2.0 4.0 tensor(-2.2156)\n",
      "\tgrad: 3.0 6.0 tensor(-4.7856)\n",
      "progress: 4 tensor(2.5447)\n",
      "\tgrad: 1.0 2.0 tensor(-0.4839)\n",
      "\tgrad: 2.0 4.0 tensor(-1.9162)\n",
      "\tgrad: 3.0 6.0 tensor(-4.1389)\n",
      "progress: 5 tensor(1.9034)\n",
      "\tgrad: 1.0 2.0 tensor(-0.4185)\n",
      "\tgrad: 2.0 4.0 tensor(-1.6572)\n",
      "\tgrad: 3.0 6.0 tensor(-3.5796)\n",
      "progress: 6 tensor(1.4237)\n",
      "\tgrad: 1.0 2.0 tensor(-0.3619)\n",
      "\tgrad: 2.0 4.0 tensor(-1.4333)\n",
      "\tgrad: 3.0 6.0 tensor(-3.0959)\n",
      "progress: 7 tensor(1.0649)\n",
      "\tgrad: 1.0 2.0 tensor(-0.3130)\n",
      "\tgrad: 2.0 4.0 tensor(-1.2396)\n",
      "\tgrad: 3.0 6.0 tensor(-2.6775)\n",
      "progress: 8 tensor(0.7966)\n",
      "\tgrad: 1.0 2.0 tensor(-0.2707)\n",
      "\tgrad: 2.0 4.0 tensor(-1.0721)\n",
      "\tgrad: 3.0 6.0 tensor(-2.3157)\n",
      "progress: 9 tensor(0.5958)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "x_data = [1.0, 2.0, 3.0]\n",
    "y_data = [2.0, 4.0, 6.0]\n",
    "w= Variable(torch.Tensor([1,0]), requires_grad=True)\n",
    "\n",
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "def loss(x,y):\n",
    "    y_pred =forward(x)\n",
    "    return (y_pred -y)*(y_pred -y)\n",
    "\n",
    "print('predic(before training)', 4, forward(4).data[0])\n",
    "\n",
    "for epoch in range(10):\n",
    "    for x_val, y_val in zip(x_data, y_data):\n",
    "        l = loss(x_val, y_val)\n",
    "        l.mean().backward()\n",
    "        print(\"\\tgrad:\",x_val, y_val, w.grad.data[0])\n",
    "        w.data = w.data - 0.01 * w.grad.data\n",
    "        \n",
    "        w.grad.data.zero_()\n",
    "        \n",
    "    print(\"progress:\", epoch, l.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict (before training) 4 tensor(4.)\n",
      "\tgrad :  1.0 2.0 tensor(-2.)\n",
      "\tgrad :  2.0 4.0 tensor(-7.8400)\n",
      "\tgrad :  3.0 6.0 tensor(-16.2288)\n",
      "progress :  0 tensor(7.3159)\n",
      "\tgrad :  1.0 2.0 tensor(-1.4786)\n",
      "\tgrad :  2.0 4.0 tensor(-5.7962)\n",
      "\tgrad :  3.0 6.0 tensor(-11.9981)\n",
      "progress :  1 tensor(3.9988)\n",
      "\tgrad :  1.0 2.0 tensor(-1.0932)\n",
      "\tgrad :  2.0 4.0 tensor(-4.2852)\n",
      "\tgrad :  3.0 6.0 tensor(-8.8704)\n",
      "progress :  2 tensor(2.1857)\n",
      "\tgrad :  1.0 2.0 tensor(-0.8082)\n",
      "\tgrad :  2.0 4.0 tensor(-3.1681)\n",
      "\tgrad :  3.0 6.0 tensor(-6.5580)\n",
      "progress :  3 tensor(1.1946)\n",
      "\tgrad :  1.0 2.0 tensor(-0.5975)\n",
      "\tgrad :  2.0 4.0 tensor(-2.3422)\n",
      "\tgrad :  3.0 6.0 tensor(-4.8484)\n",
      "progress :  4 tensor(0.6530)\n",
      "\tgrad :  1.0 2.0 tensor(-0.4417)\n",
      "\tgrad :  2.0 4.0 tensor(-1.7316)\n",
      "\tgrad :  3.0 6.0 tensor(-3.5845)\n",
      "progress :  5 tensor(0.3569)\n",
      "\tgrad :  1.0 2.0 tensor(-0.3266)\n",
      "\tgrad :  2.0 4.0 tensor(-1.2802)\n",
      "\tgrad :  3.0 6.0 tensor(-2.6500)\n",
      "progress :  6 tensor(0.1951)\n",
      "\tgrad :  1.0 2.0 tensor(-0.2414)\n",
      "\tgrad :  2.0 4.0 tensor(-0.9465)\n",
      "\tgrad :  3.0 6.0 tensor(-1.9592)\n",
      "progress :  7 tensor(0.1066)\n",
      "\tgrad :  1.0 2.0 tensor(-0.1785)\n",
      "\tgrad :  2.0 4.0 tensor(-0.6997)\n",
      "\tgrad :  3.0 6.0 tensor(-1.4485)\n",
      "progress :  8 tensor(0.0583)\n",
      "\tgrad :  1.0 2.0 tensor(-0.1320)\n",
      "\tgrad :  2.0 4.0 tensor(-0.5173)\n",
      "\tgrad :  3.0 6.0 tensor(-1.0709)\n",
      "progress :  9 tensor(0.0319)\n",
      "predict (after training) 4 tensor(7.8049)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "x_data = [1.0, 2.0, 3.0]\n",
    "y_data = [2.0, 4.0, 6.0]\n",
    "w = Variable(torch.Tensor([1.0]), requires_grad = True) # Any Random Value\n",
    "\n",
    "# our model forward pass\n",
    "def forward(x) :\n",
    "    return w * x\n",
    "\n",
    "# Loss function\n",
    "def loss(x, y) :\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred - y) * (y_pred - y)\n",
    "\n",
    "# Before Training\n",
    "print('predict (before training)', 4, forward(4).data[0])\n",
    "\n",
    "\n",
    "# Training : forward, backward, and update weight\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(10) :\n",
    "    for x_val, y_val in zip(x_data, y_data) :\n",
    "        l = loss(x_val, y_val)\n",
    "        l.backward()\n",
    "        print(\"\\tgrad : \", x_val, y_val, w.grad.data[0])\n",
    "        w.data = w.data - 0.01 * w.grad.data\n",
    "        \n",
    "        # Manually zero the gradients after updating weights\n",
    "        w.grad.data.zero_()\n",
    "    \n",
    "    print(\"progress : \", epoch, l.data[0])\n",
    "    \n",
    "# After Training\n",
    "print(\"predict (after training)\", 4, forward(4).data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n",
      "tensor([[[ 0.,  1.,  2.],\n",
      "         [ 3.,  4.,  5.]],\n",
      "\n",
      "        [[ 6.,  7.,  8.],\n",
      "         [ 9., 10., 11.]]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "t= np.array([[[0,1,2],\n",
    "              [3,4,5]],\n",
    "              [[6,7,8],\n",
    "              [9,10,11]]])\n",
    "ft=torch.FloatTensor(t)\n",
    "print(ft.shape)\n",
    "print(ft)\n",
    "# 3차원 = 각 층이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1  2]\n",
      "  [ 3  4  5]]\n",
      "\n",
      " [[ 6  7  8]\n",
      "  [ 9 10 11]]]\n"
     ]
    }
   ],
   "source": [
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.],\n",
      "        [ 3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.],\n",
      "        [ 9., 10., 11.]])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "print(ft.view([-1,3]))\n",
    "print(ft.view([-1,3]).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [2.]])\n",
      "torch.Size([3, 1])\n",
      "tensor([0., 1., 2.])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "ft=torch.FloatTensor([[0],[1],[2]])\n",
    "print(ft)\n",
    "print(ft.shape)\n",
    "print(ft.squeeze())\n",
    "print(ft.squeeze().shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "tensor([[0, 1, 2]])\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [2]])\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [2]])\n"
     ]
    }
   ],
   "source": [
    "ft=torch.tensor([0,1,2])\n",
    "print(ft.shape)\n",
    "print(ft.unsqueeze(0))\n",
    "print(ft.unsqueeze(1))\n",
    "print(ft.unsqueeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -3.1416,   9.8696, -31.0063],\n",
      "        [ -3.1384,   9.8499, -30.9133],\n",
      "        [ -3.1353,   9.8301, -30.8205],\n",
      "        ...,\n",
      "        [  3.1353,   9.8301,  30.8205],\n",
      "        [  3.1384,   9.8499,  30.9133],\n",
      "        [  3.1416,   9.8696,  31.0063]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "x=torch.linspace(-math.pi, math.pi, 2000)\n",
    "y= torch.sin(x)\n",
    "p=torch.tensor([1,2,3])\n",
    "xx=x.unsqueeze(-1).pow(p)\n",
    "print(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.nn.Sequential(\n",
    "  torch.nn.Linear(3,1),\n",
    "  torch.nn.Flatten(0,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lwh97\\anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "# 뭘까..\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "loss_fn =torch.nn.MSELoss(reduce='sum')\n",
    "learning_rate=1e-6\n",
    "for t in range(1):\n",
    "  y_pred=model(xx)\n",
    "  loss=loss_fn(y_pred,y)\n",
    "  if t %100 ==99:\n",
    "    print(t,loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 20263.716796875\n",
      "199 8061.9716796875\n",
      "299 2653.84765625\n",
      "399 665.18408203125\n",
      "499 206.87062072753906\n",
      "599 146.3748016357422\n",
      "699 123.58111572265625\n",
      "799 100.9120101928711\n",
      "899 76.0443344116211\n",
      "999 51.113243103027344\n",
      "1099 30.54082679748535\n",
      "1199 17.197309494018555\n",
      "1299 10.879783630371094\n",
      "1399 9.051859855651855\n",
      "1499 8.824041366577148\n",
      "1599 8.817851066589355\n",
      "1699 8.819120407104492\n",
      "1799 8.939785957336426\n",
      "1899 8.859026908874512\n",
      "1999 8.861298561096191\n",
      "Result: y = -2.6775487640406936e-05 + 0.8563920855522156 x + -2.6775698643177748e-05 x^2 + -0.09368261694908142 x^3\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "import math\n",
    "\n",
    "# 입력값과 출력값을 갖는 텐서들을 생성합니다.\n",
    "x = torch.linspace(-math.pi, math.pi, 2000)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# 입력 텐서 (x, x^2, x^3)를 준비합니다.\n",
    "p = torch.tensor([1, 2, 3])\n",
    "xx = x.unsqueeze(-1).pow(p)\n",
    "\n",
    "# nn 패키지를 사용하여 모델과 손실 함수를 정의합니다.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(3, 1),\n",
    "    torch.nn.Flatten(0, 1)\n",
    ")\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "# optim 패키지를 사용하여 모델의 가중치를 갱신할 optimizer를 정의합니다.\n",
    "# 여기서는 RMSprop을 사용하겠습니다; optim 패키지는 다른 다양한 최적화 알고리즘을 포함하고 있습니다.\n",
    "# RMSprop 생성자의 첫번째 인자는 어떤 텐서가 갱신되어야 하는지를 알려줍니다.\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "for t in range(2000):\n",
    "    # 순전파 단계: 모델에 x를 전달하여 예측값 y를 계산합니다.\n",
    "    y_pred = model(xx)\n",
    "\n",
    "    # 손실을 계산하고 출력합니다.\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # 역전파 단계 전에, optimizer 객체를 사용하여 (모델의 학습 가능한 가중치인) 갱신할\n",
    "    # 변수들에 대한 모든 변화도(gradient)를 0으로 만듭니다. 이렇게 하는 이유는 기본적으로 \n",
    "    # .backward()를 호출할 때마다 변화도가 버퍼(buffer)에 (덮어쓰지 않고) 누적되기\n",
    "    # 때문입니다. 더 자세한 내용은 torch.autograd.backward에 대한 문서를 참조하세요.\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 역전파 단계: 모델의 매개변수들에 대한 손실의 변화도를 계산합니다.\n",
    "    loss.backward()\n",
    "\n",
    "    # optimizer의 step 함수를 호출하면 매개변수가 갱신됩니다.\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "linear_layer = model[0]\n",
    "print(f'Result: y = {linear_layer.bias.item()} + {linear_layer.weight[:, 0].item()} x + {linear_layer.weight[:, 1].item()} x^2 + {linear_layer.weight[:, 2].item()} x^3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://tutorials.pytorch.kr/beginner/pytorch_with_examples.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 1207.18359375\n",
      "199 812.55712890625\n",
      "299 548.3020629882812\n",
      "399 371.2210388183594\n",
      "499 252.46875\n",
      "599 172.7709503173828\n",
      "699 119.24080657958984\n",
      "799 83.25648498535156\n",
      "899 59.04628372192383\n",
      "999 42.743133544921875\n",
      "1099 31.754554748535156\n",
      "1199 24.341054916381836\n",
      "1299 19.334667205810547\n",
      "1399 15.950374603271484\n",
      "1499 13.660367965698242\n",
      "1599 12.10914134979248\n",
      "1699 11.057259559631348\n",
      "1799 10.34320068359375\n",
      "1899 9.857949256896973\n",
      "1999 9.52780532836914\n",
      "Result: y = -0.019572772085666656 + 0.8380749225616455 x + 0.0033766289707273245 x^2 + -0.09067532420158386 x^3\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "import math\n",
    "\n",
    "\n",
    "class Polynomial3(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        생성자에서 4개의 매개변수를 생성(instantiate)하고, 멤버 변수로 지정합니다.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.a = torch.nn.Parameter(torch.randn(()))\n",
    "        self.b = torch.nn.Parameter(torch.randn(()))\n",
    "        self.c = torch.nn.Parameter(torch.randn(()))\n",
    "        self.d = torch.nn.Parameter(torch.randn(()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        순전파 함수에서는 입력 데이터의 텐서를 받고 출력 데이터의 텐서를 반환해야 합니다.\n",
    "        텐서들 간의 임의의 연산뿐만 아니라, 생성자에서 정의한 Module을 사용할 수 있습니다.\n",
    "        \"\"\"\n",
    "        return self.a + self.b * x + self.c * x ** 2 + self.d * x ** 3\n",
    "\n",
    "    def string(self):\n",
    "        \"\"\"\n",
    "        Python의 다른 클래스(class)처럼, PyTorch 모듈을 사용해서 사용자 정의 메소드를 정의할 수 있습니다.\n",
    "        \"\"\"\n",
    "        return f'y = {self.a.item()} + {self.b.item()} x + {self.c.item()} x^2 + {self.d.item()} x^3'\n",
    "\n",
    "\n",
    "# 입력값과 출력값을 갖는 텐서들을 생성합니다.\n",
    "x = torch.linspace(-math.pi, math.pi, 2000)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# 위에서 정의한 클래스로 모델을 생성합니다.\n",
    "model = Polynomial3()\n",
    "\n",
    "# 손실 함수와 optimizer를 생성합니다. SGD 생성자에 model.paramaters()를 호출해주면\n",
    "# 모델의 멤버 학습 가능한 (torch.nn.Parameter로 정의된) 매개변수들이 포함됩니다.\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-6)\n",
    "for t in range(2000):\n",
    "    # 순전파 단계: 모델에 x를 전달하여 예측값 y를 계산합니다.\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # 손실을 계산하고 출력합니다.\n",
    "    loss = criterion(y_pred, y)\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # 변화도를 0으로 만들고, 역전파 단계를 수행하고, 가중치를 갱신합니다.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'Result: {model.string()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8e7e9642bb2133bb3e9049961efa42b00dd232b34cd2782d376eb5751d417706"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
